{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Functions\n# 1st function: to graph time series based on TransactionDT vs the variable selected\n\ndef scatter(column):\n    fr,no_fr = (train[train['isFraud'] == 1], train[train['isFraud'] == 0])  \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,3)) \n    ax1.title.set_text('Histogram ' + column + ' when isFraud == 0')\n    ax1.set_ylim(train[column].min() - 1,train[column].max() + 1)\n    ax1.scatter(x = no_fr['TransactionDT'], y = no_fr[column], color = 'blue', marker='o')   \n    ax2.title.set_text('Histogram ' + column + ' when isFraud == 1')\n    ax2.set_ylim(train[column].min() - 1,train[column].max() + 1)\n    ax2.scatter(x = fr['TransactionDT'], y = fr[column], color = 'red', marker='o')\n    plt.show()\n    \n# 2nd function: to show a ranking of pearson correlation with the variable selected\n\ndef corr(data,column):\n    print('Correlation with ' + column)\n    print(train[data].corrwith(train[column]).abs().sort_values(ascending = False)[1:])\n    \n# 3rd function: to reduce the groups based on Nans agroupation and pearson correlation\n\ndef reduce(groups):\n    result = list()   \n    for values in groups:\n        maxval = 0\n        val = values[0]  \n        for value in values:\n            unique_values = train[value].nunique()\n            if unique_values > maxval:\n                maxval = unique_values\n                val = value \n        result.append(value)\n    return result\n\n# 4th function: to sort each column in ascending order based on its number\n\ndef order_finalcolumns(final_Xcolumns):\n    return sorted(final_Xcolumns, key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"##### Download of files.\n\nprint('Downloading datasets...')\nprint(' ')\ntrain = pd.read_pickle('/kaggle/input/1-fraud-detection-memory-reduction/train_mred.pkl')\nprint('Train has been downloaded... (1/2)')\ntest = pd.read_pickle('/kaggle/input/1-fraud-detection-memory-reduction/test_mred.pkl')\nprint('Test has been downloaded... (2/2)')\nprint(' ')\nprint('All files are downloaded')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### All the columns of train dataset.\n\nprint(list(train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NaNs Exploration\nWe will search all the columns to determine which columns are related by the number of NANs present. After grouping them, we decide to keep the columns of each group with major amount of unique values (its supposed to be the most explanatory variable)"},{"metadata":{},"cell_type":"markdown","source":"## Transaction columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# These columns are the first ones in transaction dataset.\n\ncolumns= list(train.columns[:17])\ncolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in columns:\n    print(f'{col} NaNs: {train[col].isna().sum()} | {train[col].isna().sum()/train.shape[0]:.2%}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If we look closely to % NaNs data, most of them have low number of missing information. We are keeping all the columns where % NaNs < 0.7\n\nfinal_transactioncolumns = list()\nfor col in columns:\n    if train[col].isna().sum()/train.shape[0] < 0.7:\n        final_transactioncolumns.append(col)\nprint('Final Transaction columns:',final_transactioncolumns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Group the C columns to determine which columns are related by the number of NANs present and analyze its groups independently.\n\ncolumns = ['C' + str(i) for i in range(1,15)]\ndf_nan = train.isna()\ndict_nans = dict()\n\nfor column in columns:\n    number_nans = df_nan[column].sum()\n    try:\n        dict_nans[number_nans].append(column)\n    except:\n        dict_nans[number_nans] = [column]\n\ngroup_number = 1\nfor key,values in dict_nans.items():\n    print('Group {}'.format(group_number),'| Number of NANs =',key)\n    print(values)\n    print(' ')\n    group_number += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 1 (single group)"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT\n# There is no column that does not have NaNs values so we get all the columns in the same group\n\ngroup_list = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['C1','C11','C2','C6','C8','C4','C10','C14','C12','C7','C13'], ['C3'], ['C5','C9']]\n                 \nresult = reduce(reduce_groups)\nprint('Final C columns:',result)\nfinal_ccolumns = result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## D columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Group the D columns + Dachr columns to determine which columns are related by the number of NANs present and analyze its groups independently.\n\ncolumns = ['D' + str(i) for i in range(1,16)]\ncolumns.extend(['D1achr','D2achr','D4achr','D6achr','D10achr','D11achr','D12achr','D13achr','D14achr','D15achr'])\ndf_nan = train.isna()\ndict_nans = dict()\n\nfor column in columns:\n    number_nans = df_nan[column].sum()\n    try:\n        dict_nans[number_nans].append(column)\n    except:\n        dict_nans[number_nans] = [column]\n\ngroup_number = 1\nfor key,values in dict_nans.items():\n    print('Group {}'.format(group_number),'| Number of NANs =',key)\n    print(values)\n    print(' ')\n    group_number += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 1 (single group)"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n# Despite having different number of NaNs, we are analyzing it as a single group. But due to NaNs low number in D1, we keep it as a final column.\n\ngroup_list = ['D1achr', 'D2achr', 'D3', 'D4achr', 'D5', 'D6achr', 'D7', 'D8', 'D9', 'D10achr', 'D11achr', 'D12achr', 'D13achr', 'D14achr', 'D15achr']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n# On the first group, D1achr vs D2achr --> we keep D1achr due to the low number of NaNs.\n\nreduce_groups = [['D3','D7','D5'],['D4achr','D12achr','D6achr','D15achr','D10achr', 'D11achr'], ['D8'], ['D9'], ['D13achr'],['D14achr']]\n                 \nresult = reduce(reduce_groups)\nresult.append('D1achr')\nprint('Final D columns:',result)\nfinal_dcolumns = result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## M columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Group the M columns to determine which columns are related by the number of NANs present and analyze its groups independently.\n\ncolumns = ['M' + str(i) for i in range(1,10)]\ndf_nan = train.isna()\ndict_nans = dict()\n\nfor column in columns:\n    number_nans = df_nan[column].sum()\n    try:\n        dict_nans[number_nans].append(column)\n    except:\n        dict_nans[number_nans] = [column]\n\ngroup_number = 1\nfor key,values in dict_nans.items():\n    print('Group {}'.format(group_number),'| Number of NANs =',key)\n    print(values)\n    print(' ')\n    group_number += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 1 (single group)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To analize M columns, we need to transform strings to numbers. Instead of using Label Encoder, we use a dictionary.\n\nT_F_num = dict({'F': 0, 'T': 1, 'M0': 0, 'M1': 1, 'M2': 2})\n\nfor column in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    print(f'{column}:', train[column].unique())\n    print('Transforming strings to numbers...')\n    train[column] = train[column].replace(T_F_num)\n    print(f'{column}:', train[column].unique())\n    print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n# Despite having different number of NaNs, we are analyzing it as a single group.\n\ngroup_list = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, We grouped together the columns with corr > 0.7 but in this case, no correlation is bigger than 0.7\n# That's why, in this particular case we grouped together the columns with corr > 0.5\n\nreduce_groups = ['M1'], ['M2','M3'], ['M4'], ['M5'], ['M6'], ['M7', 'M8'], ['M9']\n                 \nresult = reduce(reduce_groups)\nprint('Final M columns:',result)\nfinal_mcolumns = result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## V columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Group the V columns to determine which columns are related by the number of NANs present and analyze its groups independently.\n\ncolumns = ['V' + str(i) for i in range(1,340)]\ndf_nan = train.isna()\ndict_nans = dict()\n\nfor column in columns:\n    number_nans = df_nan[column].sum()\n    try:\n        dict_nans[number_nans].append(column)\n    except:\n        dict_nans[number_nans] = [column]\n\ngroup_number = 1\nfor key,values in dict_nans.items():\n    print('Group {}'.format(group_number),'| Number of NANs =',key)\n    print(values)\n    print(' ')\n    group_number += 1\n    \nfinal_vcolumns = list()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\ngroup_list = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = ['V1'], ['V2','V3'], ['V4','V5'], ['V6','V7'], ['V8','V9']\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group1 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27',\n              'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['V12','V13'], ['V14'], ['V15','V16','V33','V34','V31','V32','V21','V22','V17','V18'], ['V19','V20'],['V23','V24'],['V25','V26'],['V27','V28'],['V29','V30']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group2 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['V35','V36'], ['V37','V38'], ['V39','V40','V42','V43','V50','V51','V52'], ['V41'], ['V44','V45'],['V46','V47'],['V48','V49']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group3 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', \n              'V69', 'V70', 'V71', 'V72', 'V73', 'V74']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['V53','V54'], ['V55','V56'], ['V57','V58','V71','V73','V72','V74','V63','V59','V64','V60'],['V61','V62'],['V65'],\n                ['V66','V67'],['V68'], ['V69','V70']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group4 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['V75','V76'],['V77','V78'], ['V79', 'V94', 'V93', 'V92', 'V84', 'V85', 'V80', 'V81'],['V82','V83'],['V86','V87'],['V88'],['V89'],['V90','V91']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group5 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 6"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', \n              'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130',\n              'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n# We omit V107 since there is no info about corr with other columns and its unique values are 1.\n\nreduce_groups = [['V95','V101'],['V96','V102','V97','V99','V100','V103'],['V98'],['V104','V106','V105'],['V108','V110','V114','V109','V111','V113','V112','V115','V116'],\n                ['V117','V119','V118'],['V120','V122','V121'],['V123','V125','V124'],['V126','V128','V132'],['V127','V133','V134'],['V129','V131','V130'],\n                ['V135','V137','V136']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group6 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 7"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', \n              'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['V138'],['V139','V140'],['V141','V142'],['V143','V159','V150','V151','V165','V144','V145','V160','V152','V164','V166'],['V146','V147'],\n                ['V148','V155','V149','V153','V154','V156','V157','V158'],['V161','V163','V162']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group7 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 8"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V167', 'V168', 'V172', 'V173', 'V176', 'V177', 'V178', 'V179', 'V181', 'V182', 'V183', 'V186', 'V187', 'V190', 'V191', 'V192', 'V193', \n              'V196', 'V199', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = ['V167','V176','V199','V179','V190','V177','V186','V168','V172','V178','V196','V191','V204','V213','V207','V173'],['V181','V183','V182',\n                'V187','V192','V203','V215','V178','V193','V212','V204'],['V202','V216','V204','V214']\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group8 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 9"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V169', 'V170', 'V171', 'V174', 'V175', 'V180', 'V184', 'V185', 'V188', 'V189', 'V194', 'V195', 'V197', 'V198', 'V200', 'V201', 'V208', 'V209', 'V210']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['V169'],['V170','V171','V200','V201'],['V174','V175'],['V180'],['V184','V185'],['V188','V189'],['V194','V197','V195','V198'],\n                ['V208','V210','V209']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group9 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 10"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V217', 'V218', 'V219', 'V223', 'V224', 'V225', 'V226', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V235', 'V236', 'V237','V240',\n              'V241', 'V242', 'V243', 'V244', 'V246', 'V247', 'V248', 'V249', 'V252', 'V253', 'V254', 'V257', 'V258', 'V260', 'V261', 'V262', 'V263',\n              'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['V217','V231','V233','V228','V257','V219','V232','V246'],['V218','V229','V224','V225','V253','V243','V254','V248','V264','V261','V249','V258',\n                'V267','V274','V230','V236','V247','V262','V223','V252','V260'],['V226','V263','V276','V278'], ['V235','V237'],['V240','V241'],['V242','V244'],\n                ['V265','V275','V277','V268','V273'],['V269','V266']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group10 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 11"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V220', 'V221', 'V222', 'V227', 'V234', 'V238', 'V239', 'V245', 'V250', 'V251', 'V255', 'V256', 'V259', 'V270', 'V271', 'V272']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = ['V220'],['V221','V222','V259','V245','V227','V255','V256'],['V234'],['V238','V239'],['V250','V251'],['V270','V272','V271']\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group11 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 12"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V279', 'V280', 'V284', 'V285', 'V286', 'V287', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V297', 'V298', 'V299', 'V302', 'V303', 'V304',\n              'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = [['V279','V293','V290','V280','V295','V294','V292','V291','V317','V307','V318'],['V284'],['V285','V287'],['V286'],['V297','V299','V298'],\n                ['V302','V304','V303'],['V305'],['V306','V308','V316','V319'],['V309','V311','V312','V310'],['V320','V321']]\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group12 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 13"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V281', 'V282', 'V283', 'V288', 'V289', 'V296', 'V300', 'V301', 'V313', 'V314', 'V315']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = ['V281','V282','V283'],['V288','V289'],['V296'],['V300','V301'],['V313','V315','V314']\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group13 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group 14"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Time series graph based on TransactionDT.\n\ngroup_list = ['V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339']\n\nfor column in group_list:\n    scatter(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Heatmap\n\nplt.figure(figsize = (15,15))\nsns.heatmap(train[group_list].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ranking of pearson correlation.\n\nfor column in group_list:\n    corr(group_list,column)\n    print(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Based on pearson correlation, we grouped together the columns with corr > 0.7\n\nreduce_groups = ['V322','V324'],['V323','V326','V324','V327','V326'],['V325'],['V328','V330','V329'],['V331','V333','V332','V337'],['V334','V336','V335']\n\nresult = reduce(reduce_groups)\nfinal_vcolumns.extend(result)\nprint('Final V_Group14 columns:',result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final V columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of V columns:', len(final_vcolumns))\nprint(final_vcolumns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusions\nBased on previous process, we suggest keeping as final columns the ones describes below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### 1st we sort them (ascending order) with a function\n\nfinal_ccolumns = order_finalcolumns(final_ccolumns)\nfinal_dcolumns = order_finalcolumns(final_dcolumns)\nfinal_mcolumns = order_finalcolumns(final_mcolumns)\nfinal_vcolumns = order_finalcolumns(final_vcolumns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Final columns\n\nprint(f'Final Transaction columns ({len(final_transactioncolumns)}): {final_transactioncolumns}')\nprint(' ')\nprint(f'Final C columns ({len(final_ccolumns)}): {final_ccolumns}')\nprint(' ')\nprint(f'Final D columns ({len(final_dcolumns)}): {final_dcolumns}')\nprint(' ')\nprint(f'Final M columns ({len(final_mcolumns)}): {final_mcolumns}')\nprint(' ')\nprint(f'Final V columns ({len(final_vcolumns)}): {final_vcolumns}')\nprint(' ')\n\nprint('#' * 50)\n\nfinal_columns = final_transactioncolumns + final_ccolumns + final_dcolumns + final_mcolumns + final_vcolumns\nprint(' ')\nprint('Final columns:', final_columns)\nprint(' ')\nprint('Lenght of final columns:', len(final_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}